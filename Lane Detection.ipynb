{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcec4e5d-5b32-4843-96ea-cbf81f2f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kaggle\n",
    "import kagglehub\n",
    "import json\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53874744-7147-477e-9533-6bb52b9bc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2027cc8d-ec77-4511-81d1-328b262302d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/manideep1108/tusimple\n",
      "License(s): copyright-authors\n",
      "Dataset downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dateset\n",
    "\n",
    "\"\"\"\n",
    "@credits: \n",
    " - Dataset provided by Kaggle: https://www.kaggle.com/datasets/manideep1108/tusimple\n",
    "\"\"\"\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d manideep1108/tusimple \n",
    "\n",
    "# Extract the dataset\n",
    "dataset_zip = \"tusimple.zip\"\n",
    "extract_folder = \"tusimple_dataset\"\n",
    "\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "with zipfile.ZipFile(dataset_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(\"Dataset downloaded and extracted successfully.\")\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_dir = \"tusimple_dataset\"\n",
    "img_dir = os.path.join(dataset_dir, \"TUSimple/train_set/clips\")\n",
    "json_file = os.path.join(dataset_dir, \"TUSimple/train_set/label_data_0313.json\")\n",
    "\n",
    "# Check if JSON file exists\n",
    "if not os.path.exists(json_file):\n",
    "    raise FileNotFoundError(f\"Error: {json_file} not found! Ensure the dataset is correctly downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf022538-8ffc-40b1-89de-87f845ec8d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in dataset: 3626\n"
     ]
    }
   ],
   "source": [
    "# Load TuSimple Dataset and Label Images\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - PyTorch DataLoader and Dataset structure inspired by official PyTorch documentation: \n",
    "   https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    " - JSON handling and best practices for dataset preprocessing based on real-world machine learning workflows:  \n",
    "   * Kaggle discussion on data preprocessing: https://www.kaggle.com/discussions/general/222537  \n",
    "   * Scikit-Learn preprocessing guide: https://scikit-learn.org/stable/modules/preprocessing.html  \n",
    "\"\"\"\n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = {f: labels[f] for f in labels if os.path.exists(os.path.join(img_dir, f))}  # Ensure valid images only\n",
    "        self.image_files = list(self.labels.keys())\n",
    "        self.transform = transform\n",
    "\n",
    "        if len(self.image_files) == 0:\n",
    "            raise ValueError(\"No valid images found! Check dataset paths.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"WARNING: Missing image -> {img_path}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))  # Skip missing image\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[img_name]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Load TuSimple Dataset\n",
    "dataset_dir = \"./tusimple_dataset/TUSimple/train_set\"\n",
    "json_files = [\"label_data_0313.json\", \"label_data_0531.json\", \"label_data_0601.json\"]\n",
    "\n",
    "train_labels = {}\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(dataset_dir, json_file)\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = [json.loads(line) for line in f]  # JSONL format\n",
    "            for item in data:\n",
    "                raw_file = item[\"raw_file\"]  # Example: \"clips/0313-1/17260/20.jpg\"\n",
    "                if os.path.exists(os.path.join(dataset_dir, raw_file)):  # âœ… Only add existing files\n",
    "                    train_labels[raw_file] = 1 if len(item[\"lanes\"]) > 0 else 0\n",
    "    else:\n",
    "        print(f\"Warning: {json_path} not found!\")\n",
    "\n",
    "# Correct image directory (train_set is root)\n",
    "img_dir = dataset_dir  \n",
    "\n",
    "# Load dataset safely\n",
    "try:\n",
    "    train_dataset = LaneDataset(img_dir, train_labels, transform=None)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    print(f\"Total images in dataset: {len(train_dataset)}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Dataset error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "623a86ba-12e7-479d-aa29-9d2e20dd6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TuSimple JSON labels\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - Kaggle discussion on data preprocessing: https://www.kaggle.com/discussions/general/222537  \n",
    " - Scikit-Learn preprocessing guide: https://scikit-learn.org/stable/modules/preprocessing.html  \n",
    "\"\"\"\n",
    "\n",
    "json_file = './tusimple_dataset/TUSimple/train_set/label_data_0313.json'\n",
    "\n",
    "label_dict = {}\n",
    "with open(json_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "for item in data:\n",
    "    filename = item[\"raw_file\"]\n",
    "    if len(item[\"lanes\"]) > 0:\n",
    "        label_dict[filename] = 1  # Lane Present\n",
    "    else:\n",
    "        label_dict[filename] = 0  # No Lane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0c55791-f315-4e04-8ae0-0411ab0e39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - Data splitting methodology inspired by Scikit-Learn documentation:  \n",
    "   * Train-test split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  \n",
    " - PyTorch DataLoader and Dataset structure based on PyTorch documentation:  \n",
    "   * DataLoader tutorial: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html  \n",
    "\"\"\"\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_files, test_files = train_test_split(list(label_dict.keys()), test_size=0.3, random_state=42)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.3, random_state=42)  # 30% of train as validation\n",
    "\n",
    "train_labels = {k: label_dict[k] for k in train_files}\n",
    "val_labels = {k: label_dict[k] for k in val_files}\n",
    "test_labels = {k: label_dict[k] for k in test_files}\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset = LaneDataset(img_dir, train_labels, transform)\n",
    "val_dataset = LaneDataset(img_dir, val_labels, transform)\n",
    "test_dataset = LaneDataset(img_dir, test_labels, transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)  # Validation loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ae5f875-c2a9-49ff-a452-8f089349e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Data Transformations\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - Data augmentation techniques from PyTorch documentation:  \n",
    "   * Transformations: https://pytorch.org/vision/stable/transforms.html  \n",
    "   * Data augmentation best practices: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html  \n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),  \n",
    "    transforms.RandomRotation(5),  \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05), \n",
    "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)), \n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fef1b28-edb2-4a8a-9477-f2881608f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in dataset: 3626\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@credits:\n",
    " - PyTorch DataLoader and Dataset structure from official PyTorch documentation:  \n",
    "   * DataLoader tutorial: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define correct dataset paths\n",
    "dataset_dir = \"./tusimple_dataset/TUSimple/train_set\"\n",
    "json_files = [\n",
    "    \"label_data_0313.json\",\n",
    "    \"label_data_0531.json\",\n",
    "    \"label_data_0601.json\",\n",
    "]\n",
    "\n",
    "# Load and merge label data from multiple JSON files\n",
    "train_labels = {}\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(dataset_dir, json_file)\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = [json.loads(line) for line in f]  # JSONL format (line-separated JSON)\n",
    "            for item in data:\n",
    "                train_labels[item[\"raw_file\"]] = 1 if len(item[\"lanes\"]) > 0 else 0\n",
    "    else:\n",
    "        print(f\"Warning: {json_path} not found!\")\n",
    "\n",
    "# Define correct image directory\n",
    "img_dir = dataset_dir\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = LaneDataset(img_dir, train_labels, transform)\n",
    "test_dataset = LaneDataset(img_dir, test_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Debug output\n",
    "print(f\"Total images in dataset: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a78ef632-bb6f-46ad-8874-ed300b9dc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CNN Model\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - CNN architecture from PyTorch official ResNet example:  \n",
    "   * ResNet model from PyTorch documentation: https://pytorch.org/hub/pytorch_vision_resnet/  \n",
    " - Transfer learning and fine-tuning best practices based on PyTorch documentation:  \n",
    "   * Transfer learning tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html  \n",
    "\"\"\"\n",
    "\n",
    "class LaneCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaneCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False  # Freeze all layers except the final layer\n",
    "            \n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(self.model.fc.in_features, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ba6f78d-6027-46a4-9d65-201976d1d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [1/20], Batch [0/227], Loss: 1.4868\n",
      "Epoch [1/20], Batch [10/227], Loss: 0.0193\n",
      "Epoch [1/20], Batch [20/227], Loss: 0.0008\n",
      "Epoch [1/20], Batch [30/227], Loss: 0.0002\n",
      "Epoch [1/20], Batch [40/227], Loss: 0.0010\n",
      "Epoch [1/20], Batch [50/227], Loss: 0.0003\n",
      "Epoch [1/20], Batch [60/227], Loss: 0.0005\n",
      "Epoch [1/20], Batch [70/227], Loss: 0.0007\n",
      "Epoch [1/20], Batch [80/227], Loss: 0.0014\n",
      "Epoch [1/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [1/20], Batch [100/227], Loss: 0.0003\n",
      "Epoch [1/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [1/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [1/20], Batch [130/227], Loss: 0.0003\n",
      "Epoch [1/20], Batch [140/227], Loss: 0.0009\n",
      "Epoch [1/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [1/20], Batch [160/227], Loss: 0.0016\n",
      "Epoch [1/20], Batch [170/227], Loss: 0.0002\n",
      "Epoch [1/20], Batch [180/227], Loss: 0.0005\n",
      "Epoch [1/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [1/20], Batch [200/227], Loss: 0.0005\n",
      "Epoch [1/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [1/20], Batch [220/227], Loss: 0.0003\n",
      "Epoch [1/20], Loss: 0.0212, Accuracy: 0.9898\n",
      "Epoch [2/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [2/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [2/20], Batch [20/227], Loss: 0.0005\n",
      "Epoch [2/20], Batch [30/227], Loss: 0.0004\n",
      "Epoch [2/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [2/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [80/227], Loss: 0.0003\n",
      "Epoch [2/20], Batch [90/227], Loss: 0.0004\n",
      "Epoch [2/20], Batch [100/227], Loss: 0.0004\n",
      "Epoch [2/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [2/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [150/227], Loss: 0.0003\n",
      "Epoch [2/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [2/20], Batch [180/227], Loss: 0.0006\n",
      "Epoch [2/20], Batch [190/227], Loss: 0.0004\n",
      "Epoch [2/20], Batch [200/227], Loss: 0.0011\n",
      "Epoch [2/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [2/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [2/20], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [3/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [10/227], Loss: 0.0004\n",
      "Epoch [3/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [3/20], Batch [30/227], Loss: 0.0005\n",
      "Epoch [3/20], Batch [40/227], Loss: 0.0005\n",
      "Epoch [3/20], Batch [50/227], Loss: 0.0003\n",
      "Epoch [3/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [70/227], Loss: 0.0000\n",
      "Epoch [3/20], Batch [80/227], Loss: 0.0004\n",
      "Epoch [3/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [110/227], Loss: 0.0006\n",
      "Epoch [3/20], Batch [120/227], Loss: 0.0003\n",
      "Epoch [3/20], Batch [130/227], Loss: 0.0002\n",
      "Epoch [3/20], Batch [140/227], Loss: 0.0008\n",
      "Epoch [3/20], Batch [150/227], Loss: 0.0005\n",
      "Epoch [3/20], Batch [160/227], Loss: 0.0003\n",
      "Epoch [3/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [180/227], Loss: 0.0003\n",
      "Epoch [3/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [3/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [3/20], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [4/20], Batch [0/227], Loss: 0.0003\n",
      "Epoch [4/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [50/227], Loss: 0.0006\n",
      "Epoch [4/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [4/20], Batch [70/227], Loss: 0.0005\n",
      "Epoch [4/20], Batch [80/227], Loss: 0.0003\n",
      "Epoch [4/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [4/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [4/20], Batch [120/227], Loss: 0.0000\n",
      "Epoch [4/20], Batch [130/227], Loss: 0.0006\n",
      "Epoch [4/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [160/227], Loss: 0.0000\n",
      "Epoch [4/20], Batch [170/227], Loss: 0.0004\n",
      "Epoch [4/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [4/20], Batch [200/227], Loss: 0.0000\n",
      "Epoch [4/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [4/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [4/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [5/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [40/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [50/227], Loss: 0.0003\n",
      "Epoch [5/20], Batch [60/227], Loss: 0.0000\n",
      "Epoch [5/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [130/227], Loss: 0.0007\n",
      "Epoch [5/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [150/227], Loss: 0.0004\n",
      "Epoch [5/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [170/227], Loss: 0.0004\n",
      "Epoch [5/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [5/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [5/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [5/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [6/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [20/227], Loss: 0.0003\n",
      "Epoch [6/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [40/227], Loss: 0.0003\n",
      "Epoch [6/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [6/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [6/20], Batch [80/227], Loss: 0.0002\n",
      "Epoch [6/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [6/20], Batch [100/227], Loss: 0.0003\n",
      "Epoch [6/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [6/20], Batch [170/227], Loss: 0.0004\n",
      "Epoch [6/20], Batch [180/227], Loss: 0.0003\n",
      "Epoch [6/20], Batch [190/227], Loss: 0.0009\n",
      "Epoch [6/20], Batch [200/227], Loss: 0.0004\n",
      "Epoch [6/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [6/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [6/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [7/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [20/227], Loss: 0.0004\n",
      "Epoch [7/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [40/227], Loss: 0.0017\n",
      "Epoch [7/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [7/20], Batch [60/227], Loss: 0.0003\n",
      "Epoch [7/20], Batch [70/227], Loss: 0.0003\n",
      "Epoch [7/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [110/227], Loss: 0.0002\n",
      "Epoch [7/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [130/227], Loss: 0.0005\n",
      "Epoch [7/20], Batch [140/227], Loss: 0.0002\n",
      "Epoch [7/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [180/227], Loss: 0.0002\n",
      "Epoch [7/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [7/20], Batch [210/227], Loss: 0.0003\n",
      "Epoch [7/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [7/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [8/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [30/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [60/227], Loss: 0.0004\n",
      "Epoch [8/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [8/20], Batch [120/227], Loss: 0.0003\n",
      "Epoch [8/20], Batch [130/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [170/227], Loss: 0.0003\n",
      "Epoch [8/20], Batch [180/227], Loss: 0.0003\n",
      "Epoch [8/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [8/20], Batch [200/227], Loss: 0.0003\n",
      "Epoch [8/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [8/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [8/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [9/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [20/227], Loss: 0.0000\n",
      "Epoch [9/20], Batch [30/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [40/227], Loss: 0.0003\n",
      "Epoch [9/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [60/227], Loss: 0.0003\n",
      "Epoch [9/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [90/227], Loss: 0.0004\n",
      "Epoch [9/20], Batch [100/227], Loss: 0.0003\n",
      "Epoch [9/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [9/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [150/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [170/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [180/227], Loss: 0.0002\n",
      "Epoch [9/20], Batch [190/227], Loss: 0.0004\n",
      "Epoch [9/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [9/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [9/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [10/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [10/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [10/20], Batch [20/227], Loss: 0.0006\n",
      "Epoch [10/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [10/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [10/20], Batch [110/227], Loss: 0.0002\n",
      "Epoch [10/20], Batch [120/227], Loss: 0.0003\n",
      "Epoch [10/20], Batch [130/227], Loss: 0.0003\n",
      "Epoch [10/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [170/227], Loss: 0.0003\n",
      "Epoch [10/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [10/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [10/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [11/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [30/227], Loss: 0.0003\n",
      "Epoch [11/20], Batch [40/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [11/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [11/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [11/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [11/20], Batch [120/227], Loss: 0.0012\n",
      "Epoch [11/20], Batch [130/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [140/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [150/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [170/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [180/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [190/227], Loss: 0.0003\n",
      "Epoch [11/20], Batch [200/227], Loss: 0.0002\n",
      "Epoch [11/20], Batch [210/227], Loss: 0.0003\n",
      "Epoch [11/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [11/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [12/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [10/227], Loss: 0.0007\n",
      "Epoch [12/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [40/227], Loss: 0.0002\n",
      "Epoch [12/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [12/20], Batch [100/227], Loss: 0.0003\n",
      "Epoch [12/20], Batch [110/227], Loss: 0.0003\n",
      "Epoch [12/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [150/227], Loss: 0.0003\n",
      "Epoch [12/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [12/20], Batch [200/227], Loss: 0.0002\n",
      "Epoch [12/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [12/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [12/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [13/20], Batch [0/227], Loss: 0.0007\n",
      "Epoch [13/20], Batch [10/227], Loss: 0.0003\n",
      "Epoch [13/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [40/227], Loss: 0.0004\n",
      "Epoch [13/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [70/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [80/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [90/227], Loss: 0.0006\n",
      "Epoch [13/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [140/227], Loss: 0.0004\n",
      "Epoch [13/20], Batch [150/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [180/227], Loss: 0.0006\n",
      "Epoch [13/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [13/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [13/20], Batch [210/227], Loss: 0.0003\n",
      "Epoch [13/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [13/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [14/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [14/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [14/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [14/20], Batch [30/227], Loss: 0.0003\n",
      "Epoch [14/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [70/227], Loss: 0.0003\n",
      "Epoch [14/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [120/227], Loss: 0.0004\n",
      "Epoch [14/20], Batch [130/227], Loss: 0.0003\n",
      "Epoch [14/20], Batch [140/227], Loss: 0.0003\n",
      "Epoch [14/20], Batch [150/227], Loss: 0.0005\n",
      "Epoch [14/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [14/20], Batch [200/227], Loss: 0.0002\n",
      "Epoch [14/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [14/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [14/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [15/20], Batch [0/227], Loss: 0.0002\n",
      "Epoch [15/20], Batch [10/227], Loss: 0.0000\n",
      "Epoch [15/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [15/20], Batch [30/227], Loss: 0.0002\n",
      "Epoch [15/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [60/227], Loss: 0.0004\n",
      "Epoch [15/20], Batch [70/227], Loss: 0.0004\n",
      "Epoch [15/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [90/227], Loss: 0.0003\n",
      "Epoch [15/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [15/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [15/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [140/227], Loss: 0.0000\n",
      "Epoch [15/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [160/227], Loss: 0.0004\n",
      "Epoch [15/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [180/227], Loss: 0.0003\n",
      "Epoch [15/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [15/20], Batch [210/227], Loss: 0.0003\n",
      "Epoch [15/20], Batch [220/227], Loss: 0.0002\n",
      "Epoch [15/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [16/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [30/227], Loss: 0.0003\n",
      "Epoch [16/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [90/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [100/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [130/227], Loss: 0.0003\n",
      "Epoch [16/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [150/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [170/227], Loss: 0.0003\n",
      "Epoch [16/20], Batch [180/227], Loss: 0.0003\n",
      "Epoch [16/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [200/227], Loss: 0.0002\n",
      "Epoch [16/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [16/20], Batch [220/227], Loss: 0.0003\n",
      "Epoch [16/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [17/20], Batch [0/227], Loss: 0.0004\n",
      "Epoch [17/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [50/227], Loss: 0.0002\n",
      "Epoch [17/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [70/227], Loss: 0.0004\n",
      "Epoch [17/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [17/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [140/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [17/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [200/227], Loss: 0.0003\n",
      "Epoch [17/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [17/20], Batch [220/227], Loss: 0.0007\n",
      "Epoch [17/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [18/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [20/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [30/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [50/227], Loss: 0.0003\n",
      "Epoch [18/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [70/227], Loss: 0.0004\n",
      "Epoch [18/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [140/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [170/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [180/227], Loss: 0.0002\n",
      "Epoch [18/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [210/227], Loss: 0.0001\n",
      "Epoch [18/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [18/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [19/20], Batch [0/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [10/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [30/227], Loss: 0.0003\n",
      "Epoch [19/20], Batch [40/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [60/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [80/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [90/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [110/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [120/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [130/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [140/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [160/227], Loss: 0.0001\n",
      "Epoch [19/20], Batch [170/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [180/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [190/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [200/227], Loss: 0.0005\n",
      "Epoch [19/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [19/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [19/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [20/20], Batch [0/227], Loss: 0.0003\n",
      "Epoch [20/20], Batch [10/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [20/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [30/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [40/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [50/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [60/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [70/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [80/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [90/227], Loss: 0.0005\n",
      "Epoch [20/20], Batch [100/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [110/227], Loss: 0.0005\n",
      "Epoch [20/20], Batch [120/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [130/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [140/227], Loss: 0.0000\n",
      "Epoch [20/20], Batch [150/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [160/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [170/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [180/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [190/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [200/227], Loss: 0.0001\n",
      "Epoch [20/20], Batch [210/227], Loss: 0.0002\n",
      "Epoch [20/20], Batch [220/227], Loss: 0.0001\n",
      "Epoch [20/20], Loss: 0.0002, Accuracy: 1.0000\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - CNN architecture from PyTorch official ResNet example:  \n",
    "   * ResNet model from PyTorch documentation: https://pytorch.org/hub/pytorch_vision_resnet/  \n",
    " - Transfer learning and fine-tuning best practices based on PyTorch documentation:  \n",
    "   * Transfer learning tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html  \n",
    " - PyTorch training loop and optimization from PyTorch tutorials:  \n",
    "   * Training a model tutorial: https://pytorch.org/tutorials/beginner/nn_tutorial.html  \n",
    "   * Learning rate scheduler: https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.StepLR  \n",
    "\"\"\"\n",
    "\n",
    "# Initialize Model, Loss, and Optimizer\n",
    "model = LaneCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "# Train Model\n",
    "num_epochs = 20\n",
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Print batch progress every 10 batches\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Validation Step (After Each Epoch)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "print(\"Training Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "280beb78-7c58-48a2-a5e4-7810d0c86fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Trained Model\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - PyTorch saving and loading models based on PyTorch documentation:  \n",
    "   * Saving models: https://pytorch.org/tutorials/beginner/saving_loading_models.html  \n",
    "\"\"\"\n",
    "\n",
    "torch.save(model.state_dict(), \"lane_cnn_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2b0a437-d041-4e56-a4de-691e569f380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "\"\"\"\n",
    "@credits:\n",
    " - PyTorch evaluation loop inspired by PyTorch tutorials:  \n",
    "   * Model evaluation: https://pytorch.org/tutorials/beginner/saving_loading_models.html#evaluation  \n",
    "\"\"\"\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
